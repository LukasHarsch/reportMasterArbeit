%=====================================================================
\chapter{Grundlagen}
\label{sec:Grundlagen}
%=====================================================================
TODO

\section{NN basics}
%
\begin{tikzpicture}
% Feature map
\draw[] (2.6, 3.9) node {Feature maps};
\foreach \i in {7,...,1} {
	%	\draw[uniSblue, fill=uniSlightblue, thick] (0 + 0.4*\i, 0+0.4*\i) rectangle (2 + 0.4*\i, 2 + 0.4*\i);
	\pgfmathsetmacro{\j}{10}
	\j = \j + (\i*4)
	\draw[fill=black!\j!white, thick] (0.2 + 0.2*\i, 0.2 +0.2*\i) rectangle (2.2 + 0.2*\i, 2.2 + 0.2*\i);
}

% Conv 1
\draw[thick] (-1.2, 0.6) rectangle (-0.7, 1.1);
%\draw[uniSgray, dashed, thick] (-0.7, 1.1) -- (2.0, 0.8);
%\draw[uniSgray, dashed, thick] (-0.7, 0.6) -- (2.0, 0.8);
\draw[thick] (-0.7, 1.1) -- (2.0, 0.8);
\draw[thick] (-0.7, 0.6) -- (2.0, 0.8);
\draw[thick, -latex, text width=1.8cm] (0.15, -0.3) node[below]{Convolution + Activation} -- (0.15, 0.6);
\end{tikzpicture}
%
%
Intro:
- NN approximiert$ f^*$\\
- $y=f^*(x)$ mapping von Input x auf Klasse y\\
- $y=f(x,\theta)$ learns parameter of the NN\\
- $f^{(1)}$, $f^{(2)}$ und $f^{(3)}$ zu $f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x)))$ gerichteter Graph\\
- $f^{(i)}$ einzelnen Ebenen des NN\\
- Input-Layer nimmt eingangsdaten auf\\
- Ausgangsebene soll Ausgabe erzeugen, möglichst ähnlich zu y\\
- Hidden layers bestehen aus vielen parallel arbeitenden einheiten, wobie jede eine vektor-zu-skalar funktion repräsentiert. (Neuron nimmt viele werte von vorherigen EInheiten als Input un berechnet eigene Aktivierung)\\

Cost funktion:\\
- wichtiger punkt ist die Kostenfunktion in der NN architektur\\
... irgendwas mit: die Kostenfunktion gibt vor welche Aufgabe das Netz lernen soll.\\
- in vielen Fällen definiert das Model eine Verteilung $p(y|x; \theta)$. So kann das Netz mit dem principle of maximum likelihood trainiert werden. Das bedeutet die Kostenfunktion ist definiert als die negative log-Wahrscheinlichkeit. Dies wird auch bezeichnet als die cross-entropy zwischen den Trainingsdaten und den model predictions. Fomal wird die Kostenfunktion beschreiben als:
\begin{equation}
J(\mathbf{\theta}) = -E\big[\mathrm{log} p_{model}(\mathbf{y}|\mathbf{x}\big].
\end{equation}
- Durch die Spezialisierung der Kostenfunktion kann das Netz so trainiert werden das es andere Schätzungen durchführt. \\
- Oft setzt sich die gesamte Kostenfunktion aus einer primären Kostenfunktuion und einem Regularizierungsterm zusammen. \\
\\
Output units:\\
- Output units eng gekopppelt mit den Output units, da die Repräsentation des Outputs die Form der Kostenfunktion beeinflusst/vorgibt.\\
- im Prinzip können diese Units überall im Netz verwendet werden. Hier liegt der Fokus aber auf ihrer Verwendung als Output des Models.\\
- Netzwerk stellt ein Set aus hidden features bereit, definiert durch $\mathbf{h})=f(\mathbf{x};\mathbf{\theta})$. Die Output units wenden eine zusätzliche Transformation auf die feature $\mathbf{h}$ an um so die Ausgabe des Netzwerkes zu vervollständign, ensprechend der definierten Aufgabe des Netzes.\\
\\
Linear:\\
- Die einfachste Form ist eine lineare Unit. Diese wendet eine affine Transformation ohne Nichtlinearität an. Eine lineare output unit produziert einen Vektort $\hat{y}= W^t h+b$ für gegebene Features $\mathbf{h}$. lineare ouputunits werden oft verwendet um Erwartungswert einer bedingten Gaussverteilung zu schätzen:\\
\begin{equation}
p(y|x)=N(y;\hat{y},I).
\end{equation}
- Maximizing the log-likelihood is then equivalent to minimizing the mean squared error. (in the linear case)\\
\\
Sigmoid:\\
- Viele Aufgaben benötigen die Schätzung einer binären Variable $y$, z.B. die Klassifikation mit zwei Klassen. \\
- Dieses Problem wird als Bernoulliverteilung  über $y$ bedingt durch $x$ modeliert. Die Bernopulliverteilung ist definiert als...(mglw hier einfügen oder weg lassen).  Somit muss das Netz nur $P(y=1|x)$ schätzen.\\ 
\\
- Um diese Bedingung zu erfüllen wird eine sigmoid unit verwendet.\\
- Dazu wird die sigmoid unit um Probleme in dieser Form zu beschreiben. \\
\\
- Die sigmopid output unit ist definiert als:
$\hat{y}=\sigma \big(w^T h + b\big)$.
Dabei ist $\sigma$ die logistic sigmoid function.\\
-----\\
- (3.10) logistic sigmoid:
\begin{equation}
	\sigma(x) = \frac{1}{1+e^{-x}}
\end{equation}
- die logistic sigmoid funktion wird im Allgemeinen verwendet um die Parameter $\phi$ einer Bernoulliverteilung zu ermitteln, da die Funktion im Bereich (0,1) definiert ist. Somit liegt die Funktion im Wertebereich des Parameter $\phi$ der Bernoulliverteilung.\\
- die Sigmoidfunktion ist gesättigt falls ihr Argument sehr positiv oder sehr negativ ist. Somit ist die Funktion sehr flach und unempfindlich gegenüber kleinen Änderungen im Eingnang.\\
-----\\
- Zuerst lineare layer $z=w^T h + b$. Danach sigmoid aktivierung funktion um z in eine Wahrscheinlichkeit zu konvertieren.\\
\\
Softmax:\\
Die softmax Funktion kann verwendet werden um eine Wahrscheinlichkeitsverteilung über eine diskrete Variable mit $n$ möglichen Werten zu beschreiben. Im Grunde eine Verallgemeienrung der sigmoid funktion. Meistens wird die softmax Funktion als Ausgang einer Klassifikation verwendet um die Wahrscheinlichkeitsverteilung über $n$ verschiedenen Klassen zu repäsentieren.\\
- generalizierung der sigmoid funktion zur schätzung der bernoulliverteilung. 
ergibt $\hat{y}_i=P(y=i|x)$. Dabei soll nciht nur jedes Element von $\hat{y}_i$ zwischen 0 und 1 liegen sonder auch die Summe des gesamten Vektors = 1 sein.\\
- Somit gilt der Ansatz allgemein für multinoulli verteilungen\\
- Wie zuvor wird zuerst eine lineare Layer $z=w^T h + b$ angewendet. Anschließend wird die softmax aktivierung angewendet, beschreiben durch: $\mathrm{softmax}(z)_i = \frac{e^{z_i}}{\sum_j e^{z_i}}$\\  
\\
- vllt beispiel aus Präsi wie beliebige Werte über die softmax in Verteilung umgerechnt werden + Bild von MNIST mit zugehörigem Blakendiagram für die Verteilung\\
\\
Hidden layer:\\
- Im allgemeinen werden die hidden units als Funktion beschreiben welche auf einen Vektor aus Eingangsdaten \textbf{x} eine affine Transformation $z=W^Tx+b$ durchführt. Dabei beschreibt $W$ eine Gewichtsmatrix und $b$ einen Bias-Vektor. Anschließend wird eine elementweise nichtlineare Funktion $g(z)$ angewendet. Die Funktion $g(z)$ wird Aktivierungsfunktion genannt.\\
- hidden unit für jede Ebene werden somit durch $h^{(l)}=g(W^{(l)T}x+b^{(l)})$ beschrieben, wobei $l$ die jeweile Ebene vorgibt.\\
- Die meisten hidden units unterscheiden sich durch eine unterschiedliche Wahl der Aktivierungsfunktion $g(z)$.\\
\\
- häufig werden rectified linear units (ReLU) verwendet mit der aktivierungsfunktion:
$g(z)=max\{0,z\}$.\\
- Diese verhalten sich wie eine lineare Aktivierung nur dass die Outputs über die linke Hälfte der Domäne =0 sind.\\
- Relun wird typischerweise ontop einer affinen Transformation angewandt:
$h=g(W^Tx+b)$.\\
\\
- Erweiterung ist die leaky ReLU $f(x)= 
\begin{cases}
	x & if x > 0\\
	\alpha x & otherwise
\end{cases}
$\\
- Darüberhinaus existieren viele weitere Aktivierungsfunktionen.\\
\\
Conv netzworks:\\
- Erweiterung der bisher beschreibenen NN sind die convolutional neural networks (CNN).\\
- Großen Erfolg in der Bildverarbeitung, bei welchem der Input als 2D grid von pixeln betrachtet werden kann.\\
- wie der Name sagt wird in diesen Netzen eine convolituional Operator eingeführt.\\
\\
Conv operator:\\
- Convolution im Allgemeinen ist eine Operation zwischen zwei Funktionen $x$ und $w$. Dabei wird das Integral der punktweisen Multiplikation der zwei Funktionen gebildet, wobei eine Funktion gedreht und verschoben ist. - Dies ist definiert als:
\begin{equation}
s(t)=(x\star w)(t)=\sum_{a=-\infty}^{\infty}x(a)w(t-a).
\end{equation}
- Bei der Anwendung von CNNs ist der Eingang typischerweise ein multidimensionaler Array aus Daten. Der Kernel beschreibt ein mutlidimensionalen Array aus Parameter die während des Trainings vom Lernalgorithmus angepaqsst werden.\\
- oftmals wird convolution über mehr als eine Achse berechnet. Für ein zweidimensionals Bild $I$ als Input beispielsweise kann ein zweidimensionaler Kernel $K$ verwendet werden. Die Convolution resultiert in:
\begin{equation}
S(i,j)=(I\star K)(i,j)=\sum_{m}\sum_{n} I(m,n)K(i-m,j-n).
\end{equation}
- Erwähnen, dass für die Implementierung einige Umformungen angewendet werden, flipping; cross-correlation 
- Bild von Faltungsprozess und Referenze einfügen.\\
%
\textbf{Motivation}\\
- CNNs haben drei Ideen welche heflen das machine learning Verhalten zu verbessern: sparse interactions, parameter sharing and equivariant
representations.\\
- Traditionelle NN Ebenen verwenden eine Matrix multiplikation zwischen einer Matrix aus Parametern und einem weiteren Paramater. Das bedeutet jede Output unit interagiert mit jeder Eingangs unit. CNN dagegen haben eine \textbf{sparse interaction}. Dies wird erreicht indem kleiner als der Input ist. Ein Bild beispielsweise besteht aus einer vielzahl von Pixeln. Ein kleinerer Kernel betrachtet nur wenige Pixel aus dem gemsaten Bild und kann somit aussagekräftige Features wie Kanten und Ecken in dem Bild erkennen. Darüber hinaus werden weniger Parameter benötigt wodurch der Speicher- und Rechenaufwand reduziert wird.\\
- \textbf{parameter sharing:} In traditionlellen NN wird jedes Element der Gewichtsmatrix genau ein mal verwendet um den Ausgang einer Ebene zu berechnen, indem jedes Gewicht mit einem Element des Inputs multipliziert wird und danach nicht mehr verwendet wird. In einem CNN dagegen wird jeder Filter eines Kernels an jeder Position des Inputs verwendet. Somit wird an Stelle eines seperaten Parameterset für jede Position im Input nur ein Parameterset für alle Positionen benötigt.  \\ 
%
- Des Weiteren haben CNN die Eigenschaft \textbf{equivariance to translation}. Für eine Funktion bedeutet dies, wenn sich der Input ändert, so ändert sich der Output gleichermaßen. Formel geschrieben ist eine Funktion $f(x)$ equivariant zu einer Funktion $g$ falls $f(g(x))=g(f(x))$ ist.\\
- Beispielsweise soll die Funktion $I$ die Pixel eines Bildes beschreiben. Das Mapping auf eine andere Funktion soll beschreiben werden durch $I'=g(I)$, wobei gilt $I'(x,y)=I(x-1,y)$. Dadurch wird jedes Pixel in dem Orginalbild um eine Einheit verschoben. Durch die equivariance Eingenschaft ergibt sich der selbe Output wenn zuerst die Transformation $g$ und dann die Convolution angewendet wird bzw. erst die Conv, dann die Trafo $g$.\\
- Diese Eigenschaft ist beispielsweise in der Bildverarbeitung sehr hilfreich. Hier kann die erste Conv-Ebene Feautres wie z.B. Ecken oder Kanten erkennen. Da Ecken und Kanten über das gesamte Bild verteilt auftreten können ist es hilfreich die Paramter über das gesamte Bild zu teilen. \\
%
\\
\\
%
\textbf{Pooling}
%
-Der Conv-Oprator tritt oftmals in Verbindung mit dem Pooling-Operator auf. Das Pooling wird auf den Output der Conv-Ebene angewendet und ersetzt diesen durch eine Zusammnfassung der nahegelegenen Outputs. Der max Pooling-Operator beispielsweise fasst eine rechteckige Umgebung der Outputs zusammen durch Ausgabe des maximalen Werts in dieser Umgebung. \\
- Darüberhinaus existiren viele weitere Pooling-Verfahren.\\
- Ziel des Pooling ist es die Filter invariant gegnüber kleinen Veränderungen im Input zu machen. Invariant bedeutet, dass durch eine kleine Änderung des Inputs die meisten pooled Outputs unverändert bleiben.\\
- Diese Eingenschaft ist nützlich, da es oftmals von größerem Interesse ist zu erkennen ob Features existieren anstatt deren exakte Position zu erhalten.\\
- Beispielsweise in der Gesichtserkennung ist es ausreichen zu erkennen, dass sich ein Auge auf der rechten Seite und eines auf der linken Seite befindet, anstatt die Position der Augen auf das pixel genau zu bestimmen. 
- Auch ist es möglich die Pooling-Region um jeweils $k$ Pixel zu verschieben. Dies führt dazu, dass die Anzahl der Output units ca. $k$-mal weniger werden und somit deutlich weniger Inputs in der nächsten Ebene verarbeitet werden müssen. Dadurch kann der Rechenaufwand des Netzes verringert werden.
\\goodfellow S.350\\
%
%
%
%
%
\section{Neuronale Netze}
%\begin{comment}
- NN approximiert$ f^*$\\
- $y=f^*(x)$ mapping von Input x auf Klasse y\\
- $y=f(x,\theta)$ learns parameter of the NN\\
- $f^{(1)}$, $f^{(2)}$ und $f^{(3)}$ zu $f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x)))$ gerichteter Graph\\
- $f^{(i)}$ einzelnen Ebenen des NN\\
- Input-Layer nimmt eingangsdaten auf\\
- Ausgangsebene soll Ausgabe erzeugen, möglichst ähnlich zu y\\
- Hidden layers bestehen aus vielen parallel arbeitenden einheiten, wobie jede eine vektor-zu-skalar funktion repräsentiert. (Neuron nimmt viele werte von vorherigen EInheiten als Input un berechnet eigene Aktivierung)\\
- Im allgemeinen werden die hidden units als Funktion beschreiben welche auf einen Vektor aus Eingangsdaten \textbf{x} eine affine Transformation $z=W^Tx+b$ durchführt. Dabei beschreibt $W$ eine Gewichtsmatrix und $b$ einen Bias-Vektor. Anschließend wird eine elementweise nichtlineare Transformation $g(z)$ angewendet. Die Transformation $g(z)$ wird aktivierungsfunktion genannt. \\
- hidden unit für jede Ebene werden somit durch $h^{(l)}=g(W^{(l)T}x+b^{(l)})$ beschrieben, wobei $l$ die jeweile Ebene vorgibt.\\

- häufig werden rectified linear units verwendet mit der aktivierungsfunktion $g(z)=max\{0,z\}$.\\
- Erweiterung ist die leaky ReLU $f(x)= 
\begin{cases}
x & if x > 0\\
\alpha x & otherwise
\end{cases}
$\\
- Es existieren viele weitere Aktivierungsfunktionen.\\



%\end{comment}
%
%
%
%
%
In diesem Kapitel werden wichtigsten Grundlagen von neuronalen Netzen (NN) erläutert. Das Ziel von neuronalen Netzen ist es eine Funktion $f^*$ zu approximieren. Für eine Klassifikation beispielsweise mappt die Funktion $y=f^*(x)$ die Eingangsdaten $x$ auf eine Klasse $y$. Das Mapping in einem neuronalen Netz ist definiert als $y=f(x;\theta)$, wobei das Netz die Werte der Parameter $\theta$ lernt um die Funktion bestmöglichst zu approximieren. Die Zusammensetzung der Funktionen in einem NN können als Model eines gerichteten Graphen betrachtet werden. Ein Beispiel ist die Verkettung von $f^{(1)}$, $f^{(2)}$ und $f^{(3)}$ zu $f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x)))$. Die Funktionen $f^{(i)}$ beschreiben dabei die verschiedenen Ebenen in einem NN. Während des Trainings wird versucht $f(x)$ so zu berechnen das sie zu $f^*(x)$ passt. Das Trainingssample aus $(x,y)$ gibt dabei vor, dass die Ausgabeebene des Netzes einen Wert produzieren soll, welcher möglichst ähnlich zu $y$ ist. Das Verhalten der inneren Ebenen wird nicht direkt vorgegeben. Der Trainingsalgorithmus muss dann entscheiden wie die inneren Ebenen zu verwenden sind um $f^*$ zu approximieren und die gewünschte Ausgabe zu erhalten.\\   
%
%
%
%
%
%
Hierzu wird beispielhaft ein simples feedforward NN betrachtet. Der Aufbau wird in Abbildung XYZ veranschaulicht. Ein CNN besteht aus einer \textbf{Eingangsebene}, mehreren \textbf{versteckten Ebenen} im inneren und einer \textbf{Ausgangsebene}. 
%
\begin{itemize}
 \item input
 \item hidden layer
 \item output softmax
 \item convolution discrete equaltion, maybe image, kernel is learning filter, imgage of real-world filter 
 \item activation sigmoid, relu
 \item striding
 \item flat
 \item fully connected layer
 \item Training (SGD)
\end{itemize}
%
%
\section{Semi-überwachtes Lernen}
Das Themengebiet maschinelles Lernen umfasst zwei grundsätzlich verschiedene Aufgabentypen, \textbf{unübrwachtes} und \textbf{übrwachtes} Lernen. Für unüberwachtes Lernen wird ein Set $X=(x_1,\ldots,x_n)$ aus $n$ Exmplaren/Datenpunkten/Samples benötigt, wobei $x_i \in \mathcal{X}$ für alle $i \in [n] := {1,\ldots,n}$. Es wird davon ausgegangen, dass die Punkte unabhängig und gleichverteilt (i.i.d.) von einer Verteilung $\mathcal{X}$ mit der Dichte $p(x)$ gezogen werden. Jeder Eingang $x_i$ stellt ein seperates Feature darstellt. In einem Bild beispielsweise sind die Features die jeweiligen Werte der Pixel. Das Zeil von unüberwachtem Lernen ist es interessante Strukturen in den Daten $X$ zu finden. Dabei ist es üblich die Dichte oder ein bekanntes Funktional zu schätzen welches mit hoher Wahrscheinlichkeit $X$ generiert. Viele Techniken für die Dichteschätzung benötigen eine Latentvariable (unüberwachtes Klassenlabel) $y$. Die Latentvariable $y$ ist eine für das Problem entsprechend modellierte Größe und nicht zu vergleichen mit Klassenlabel bei einer Klassifikation, welches real Klasse wiederspiegeln soll. $y$ wird anschließend verwendet um $P(x)$ als eine gemischte Verteilung $\sum_{y=1}^M P(x|y)P(y)$ zu schätzen. Weitere Anwendungen für unüberwachtes Lernen sind biespielsweise Clustering, Outliererkennung oder Dimensionsreduzierung.\\
%
Im Gegensatz zu unüberwachtem Lernen benötigt überwachtes Lernen ein Trainingsdatenset aus Paaren von $(x_i,y_i)$. Dabei beschreibt $y_i$ das Klassenlabel oder das Ziel von $x_i$. Das Ziel von überwachtem Lernen ist die Schätzung eines funktionalen Zusammenhangs bzw. ein mapping von $x\rightarrow y$. Dabei gilt es die Wahrscheinlichkeit des Klassifikationsfehlers zu minimieren. Bei einer Klassifikation kann so durch Schätzung der Dichte $p(y|x)$ den Eingangsdaten $X$ die zugehörigen Klassenlabels $y$ zugewiesen werden. In dieser Arbeit wird das überwachte Lernen verwendet um \textbf{Convolutional Neural Networks} zu trainieren. Ziel des Netzes ist es eine Funktion $f*$ zu approximieren. Für eine Klassifikation mappt die Funktion $y=f*(x)$ die Eingangsdaten $x$ auf eine Klasse $y$. Das Mapping in einem neuronalen Netz ist definiert als $y=f(x;\theta)$ wobei das Netz die Werte der Parameter $\theta$ lernt um die Funktion bestmöglichst zu approximieren.\\
%
Ein weiterer Aufgabentyp ist das \textbf{semi-überwachte} Lernen (SSL), welcher zur kathegorie des des überwachten Lernens gehört, da auch hier das Ziel ist den Klassifikationsfehler zu minimieren. Wie zuvor wird ein Datenset mit den zugehörigen Labeln $D_l=\{(x_i,y_i)|i=1,\ldots,n\}$ benötigt, welche i.i.d. von $P(x,y)$ gezogn wurden. Darüber hinaus existiert ein Datenset ohne Klassenlabel $D_u=\{x_{n+j}|j=1,\ldots,m\}$ aus der Verteilung$P(x)$. Semi-überwachtes Lernen ist besonders interessant wenn $m>>n$, da ungelabelete Daten oftmals günstiger und einfacher zu erhalten sind als gelabelte Daten. Das vorgehen bei SSL bsteht aus zwei Schritten. Im ersten werden Methoden des unüberwachten Lernens verwendet um mit Hilfe einer Latentvariabel $y$ die Verteilung $P(x)$ zu schätzen. Anschließend können die Latentgruppen mit den beobachteten Klassen aus $D_l$ verbunden werden. Dieses Vorgehen wird bei den Verfahren \textbf{Variational Autoencoder} und \textbf{Generative Adversarial Network} verwendet.\\  
%http://www.acad.bg/ebook/ml/MITPress-%20SemiSupervised%20Learning.pdf
\cite{Goodfellow-et-al-2016}
%
%
%
\subsection{Generative Netze}
Das Ziel von maschinellem Lernen ist die Approximation eines Modells das möglichst allgemein gilt und somit neue bisher unbekannte Daten verarbeiten kann. Der beste Weg solch ein Model zu verallgemeinern ist es, dass Model mit mehr Daten zu trainieren. Allerdings ist die Menge der Trainingsdaten oft limitiert. Aus diesem Grund können Fake-Daten generiert werden um den Datensatz künstlich zu erweitern. Bei einer Klassifikation beispielsweise soll den Eingangsdaten $\mathbf{x}$ eine ein Label $y$ zugewiesen werden. Das bedeutet der Klassifikator muss möglichst invariant gegenüber einer breiten Reihe von Transformationen sein. Neue Trainingsdaten $(\mathbf{x},y)$ können somit einfach durch eine Transformation der Eingangsdaten $\mathbf{x}$ aus dem ursprünglichen Trainingsset erzeugt werden. Bekannte Methoden sind z.B. Umwandlung einiger Pixel in einem Bild, Rotation des Bildes oder eine Veränderung der Skalierung des Bildes. Auch kann es bereits genügen den Eingangsdaten ein Rauschen hinzuzufügen um den Datensatz zu erweitern.\\
\cite{Goodfellow-et-al-2016}
\\
%
Darüber hinaus existieren weitere komplexere Methoden um Fake-Daten künstlich zu erzeugen. Diese werden generative Modelle genannt. Ziel ist es neue, ungesehene Daten zu erzeugen die ähnlich zu den ursprünglichen Daten sind aber nicht genau gleich sind. Dazu wird ein Set aus Daten $X$ mit einer unbekannten Verteilung $P_{unb.}(X)$ benötigt. Es gilt ein Model zu trainieren welches eine Verteilung $P(X)$ lernen soll, sodass $P(X)$ möglichst ähnlich zu $P_{unb.}(X)$ ist. Aus dieser gelernten Verteilung $P(X)$ kann gesamplet werden um neue Daten zu erzeugen. In dieser Arbeit werden zwei Arten von generativen Netzen untersucht, der "variational autoencoder" und das "generative adversarial network".\\   
\cite{2016arXiv160605908D}
%
%
\subsubsection{Variational Autoencoder}
%
%
\begin{figure}
%
\tikzstyle{int}=[draw]
\begin{tikzpicture}
	[auto,>=latex']
	\node [int, regular polygon,regular polygon sides=3, shape border rotate=-90] (Enc) {\begin{tabular}{c} Encoder \\ $Q(z|X)$ \end{tabular}};
	\node (Input) [left of=Enc, node distance=4cm, coordinate] {Input};
	\node [int, rectangle, minimum width=0.5cm, minimum height=2cm] (Lat) [right of=Enc, node distance=4cm] {$z$};
	\node (Middle2) [left of=Lat, node distance=3cm, coordinate] {Middle2};
	\node [int, regular polygon,regular polygon sides=3, shape border rotate=90, label=above:{Decoder}] (Dec) [right of=Lat, node distance=4cm] {\begin{tabular}{c} Decoder \\ $P(X|z)$ \end{tabular}};
	\node (Middle) [left of=Dec, node distance=3cm, coordinate] {Middle};
	\node [coordinate] (end) [right of=Dec, node distance=4cm]{};
	
	\path[->] (Input) edge node {Input $X$} (Enc);
	\path[->] (Enc) edge node {} (Lat);
	\path[->] (Lat) edge node {} (Dec);
	\draw[->] (Dec) edge node {Output $\hat{X}$} (end) ;
\end{tikzpicture}
%
\caption[VAEblock]{Blockschaltbild eines Autoencoders}
\label{VAEblock}
\end{figure}
%
%
Die Grundidee eines Autoencoders (AE) ist die Eingangsdaten über einen Zwischenraum auf die Ausgangsdaten zu kopieren. Dabei beschreibt der Zwischenraum einen Code welcher die Eingangsdaten repräsentiert. Der AE besteht aus zwei hintereienander gschalteten Netzen. Der strukturelle Aubau wird in Abbildung \ref{VAEblock} dargestellt. Das erste Netz, der \textbf{Encoder} $Q$ ist eine Funktion $z=f(X)$ welche die Eingangsdaten $X$ in einen Zwischenraum $z$ mappt. Der Zwischenraum wird im folgenden als Latentraum bezeichnet. Das zweite Netz, der \textbf{Decoder} $P$ soll aus den kodierten Daten $z$ die ursprünglichen Daten $X$ rekonstruieren. Der Autoencoder soll dabei nicht nur das Mapping $g(f(x))=x$ lernen. Oft wird der AE so eingeschränkt das er wichtige Eigenschaften der Eingangsdaten lernt. So kann der AE beispilsweise die Verteilung $P(X)$ der Eingangsdaten lernen.\\
%
Der \textbf{Latentraum} ist eine Vektor $\mathbf{z}$ aus sogenannten Latentvariablen $z$. Dabei können Samples von $\mathbf{z}$ entsprechend einer Wahrscheinlichkeitsdichtefunktion (PDF) $P(\mathbf{z})$ entnommen werden. Im weiteren Verlauf wird $\mathbf{z}$ als normal verteilt angenommen, d.h. $\mathbf{z}\sim\mathcal{N}(0,I)$, wobei $I$ die Einheitsmatrix darstellt. Die multidimensionale Verteilung von $P(\mathbf{z})$ in $d$ Dimensionen setzt sich somit aus einem Set von $d$ normal verteilten Variablen $z$ zusammen.\\
%
Wie breits erwähnt ist das Ziel ein Model der Daten zu finden, d.h. der AE soll die Verteilung $P(X)$ der Eingangsdaten $X$ lernen. Dazu wird eine Funktion $X=f(z;\theta)$ benötigt, welche die Latentvariablen $z$ nach $X$ mappt. Der Vektor $\theta$ definiert die Parameter der Netzes. Es gilt $\theta$ so zu optimieren, dass durch ziehen von Samples $z$ aus $P(z)$ die Funktion $f(z;\theta)$ mit hoher Wahrscheinlichkeit Ausgaben produziert welche gleich den $X$'s aus dem Datenset sind. Dieser Zusammenhang kann nach dem Gesetz der totalen Wahrscheinlichkeit beschreiben werden als:
%
\begin{equation}
P(X)=\int \underbrace{P(X/z,\theta)}_{f(z;\theta)}P(z)dz.
%\label{eq:totaleWahrscheinlichkeit}
\end{equation}
%
Wenn das Model mit hoher Wahrscheinlichkeit Beispiele aus dem Trainingsdatensatz produziert ist es ebenfalls sehr wahrscheinlich, dass das Model Samples erzeugen kann die ähnlich aber nicht gleich den Trainingsdaten sind.\\
%
Das bisherige Konzept wird im Folgenden zu einem variational Autoncoder (VAE) erweitert. Hierbei ist das Ziel die Verteilung $P(z)$ aus $P(z|X)$ zu erschließen. Dies macht Sinn, da $z$ so eine Verteilung annimmt welche mit hoher Wahrscheinlichkeit $X$ produzieren kann. Diese Methode wird variational inference (VI) genannt. Die Idee ist die tatsächliche Verteilung $P(z|X)$ mittels einer einfacheren Verteilung $Q(z|X)$ zu modellieren, z.B. eine Gaussverteilung. Dabei gilt es den Unterschied zwischen der tatsächlichen und der modellierten Verteilung zu minimieren. Dazu wird die Kullback-Leibler (KL) Divergenz verwendet. Diese Metric beschreibt den Unterschied zweier Verteilungen, hier den Unterschied zwischen $P(z|X)$ und $Q(z|X)$. Die KL Divergenz wird formliert als:
%
\begin{equation}
D_{KL}\big[Q(z|X)||P(z|X)\big] = E\big[\mathrm{log} Q(z|X) - \mathrm{log} P(z|X)\big].
\end{equation}
%
Mit der Anwendung der Bayes-Regel und einigen Transformationen ergibt sich daraus die Kostenfunktion für den VAE als:
%
\begin{equation}
\mathrm{log} P(X) - D_{KL}\big[Q(z|X)||P(z|X)\big] = E\big[ \mathrm{log} P(X|z)\big] - D_{KL}\big[Q(z|X)||P(z)\big].
\label{eq:KL_loss}
\end{equation}
%
Die linke Seite der Gleichung \ref{eq:KL_loss} beschreibt die kostenfunktion des VAE. Wie bereits erwähnt ist das oberste Ziel des VAE die Wahrscheinlichkeit von $P(X)$ zu maximieren. Hier beschreiben durch die log-Wahrscheinlichkeit $\mathrm{log} P(X)$. Hinzu kommt der Regularizierungsterm $D_{KL}\big[Q(z|X)||P(z|X)\big]$ welcher sicherstellt, dass $Q$ Latentvariablen $z$ produzieren kann aus denen sich anschließend $X$ reproduzieren lässt. Die rechte Seite von Gleichung \ref{eq:KL_loss} ist eine Darstellung die mittels stochastic gradient descent Methoden optimiert werden kann. Wie im oberen Teil bereits bschreiben wird die Verteilung von $P(z)$ als Standartnormalverteilung $\mathcal{N}(0,I)$ definiert. Somit soll auch $Q(z|X)$ eine Gaussverteilung mit Erwartungswert $\mu(X)$ und Varianz $\Sigma(X)$ werden. Für die KL Divergenz ergibt sich durch Einsetzen diesen beiden Verteilungen:
%
%
\begin{equation}
 D_{KL}\big[N(\mu(X),\Sigma(X))||N(0,I)\big] = \frac{1}{2}\sum_k\Big(\Sigma(X)+\mu^2(X)-1-\mathrm{log}\Sigma(X)\Big).
\end{equation}
%
- Um den Eingang $z$ für den Encoder zu erhalten müssen Sample aus eine Gaussverteilung gezogen werden, welche durch die Parameter aus dem DEcoder definiert wird. Dies führt allerdings zu Problemen bei der Optimierung mit gradient descent, da der Sampling-Prozess keine Gradienten besitzt.\\
- Damit das Netz differenzierbar bleib wird der sogenannte Reparametrisierungstrick angewandt.
- Eine Standartnormalverteilung lässt sich in jede Gaussverteilung konvertieren, falls deren Erwartungswert und Varianz bekannt sind. Somit genügt es Sample aus einer Standartnormalverteilung $\epsilon Tilde N(0,1) $ zu ziehen und diese mit dem Erwartungswert $\mu$ und der Varianz $\Sigma$ aus dem Encoder nach $z$ zu konvertieren:
\begin{equation}
z=\mu(X)+\Sigma^{\frac{1}{2}}(X)\epsilon.
\end{equation}
Somit wird der eigentliche Sampling-Prozess aus dem Netz herausgezogen. Lediglich $\mu$ und $\Sigma$ sind noch Teil des Netzes und die Backpropagation kann problemlos durchgeführt werden. 


%
%
\subsubsection{GAN}
TODO

\subsection{Attack-Defence}

\section{Akustic-Preprocessing}
Dieses Kapitel beschreibt die 
